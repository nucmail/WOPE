This repository contains an implementation of WOPE – a novel offline reinforcement learning (ORL) algorithm that addresses the challenges of learning from heterogeneous datasets. WOPE is designed to robustly extract policies from offline data generated by multiple behavioral sources by adaptively weighting trajectories based on their cumulative rewards and by employing a conservative pseudo-exploration strategy.

Overview

In realistic ORL scenarios, data is often collected from diverse sources such as expert demonstrations, suboptimal policies, or even random exploratory behaviors. Uniformly treating such heterogeneous data can lead to suboptimal policy updates. WOPE tackles these challenges through two main components:
	•	Trajectory Quality-Weighted Policy Extraction:
WOPE calculates an adaptive importance weight for each trajectory based on its cumulative reward. This approach prioritizes high-quality trajectories while still leveraging valuable information from lower-quality ones.
	•	Conservative Pseudo-Exploration:
WOPE uses a conservative value function and a Gaussian Mixture Model (GMM)-based cross-entropy method to explore actions with higher estimated values. This strategy helps to refine the policy by effectively “correcting” suboptimal data toward better performance without further environment interactions.

Repository Structure
	•	dataset.py
Contains functions and classes for loading and preprocessing offline datasets.
	•	replaybuffer.py
Implements the replay buffer to store trajectories and facilitate efficient sampling during training.
	•	wope.py
Provides the core implementation of the WOPE algorithm, including adaptive weighting and conservative pseudo-exploration mechanisms.
	•	main.py
The main training and evaluation script. Use this file to run experiments on benchmark environments.

Prerequisites

To run the code, ensure you have the following installed:
	•	Python 3.7 or higher
	•	PyTorch (version 1.7 or later recommended)
	•	NumPy
	•	Gym (if using standard RL environments)
	•	Other dependencies as specified in the requirements.txt (if provided)

You can install the necessary packages via pip: